{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "4th week.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMvdxCSXODCxzFBwz8cGDui",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/julija-dmrk/data-mining/blob/main/4th_week.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GZ675e2cWOYg"
      },
      "source": [
        "logistic regression classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RTdDEuFyWNXf"
      },
      "source": [
        "import matplotlib.pyplot as plt   # visualization\r\n",
        "import seaborn as sns             # visualization\r\n",
        "import numpy as np                # data manipulation\r\n",
        "import pandas as pd               # data manipulation, data processing, CSV file I/O (e.g. pd.read_csv\r\n",
        "from sklearn import datasets, metrics, pipeline\r\n",
        "from sklearn.neighbors import KNeighborsClassifier\r\n",
        "from sklearn.linear_model import LogisticRegression\r\n",
        "\r\n",
        "# from sklearn.neighbors import NearestNeighbors\r\n",
        "from sklearn.preprocessing import StandardScaler\r\n",
        "from sklearn.model_selection import KFold, StratifiedKFold, LeaveOneOut, cross_val_score, cross_validate, GridSearchCV, train_test_split\r\n",
        "from sklearn.model_selection import cross_val_score, cross_validate "
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4V2hlm36mJRo"
      },
      "source": [
        "url = \"https://raw.githubusercontent.com/VitaT/ML-python/main/data/suicides.csv\"\r\n",
        "data = pd.read_csv(url)"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rf8KJpRamebm"
      },
      "source": [
        "# cleaning up\r\n",
        "# spliting country-year column\r\n",
        "data['year'] = data[\"country-year\"].str[-4:]\r\n",
        "data['country'] = data[\"country-year\"].str.split(\"\\d+\", expand = True)[0]\r\n",
        "# removing ID and country-year columns\r\n",
        "data.drop([\"ID\", \"country-year\"], axis=1, inplace=True)"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "haNU8R6vmjS0"
      },
      "source": [
        "# renaming columns for more convenient use\r\n",
        "data.rename(columns={'gdp_for_year ($)':'gdp_year', 'gdp_per_capita ($)':'gdp_capita', 'suicides/100k pop':'suicide_norm', \"HDI for year\":\"hdi_year\"}, inplace=True)"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M1lrznYTmma3"
      },
      "source": [
        "data.isna().sum()\r\n",
        "# suicide per 100k people can be calculated from suicides_no and population. Let's check it they are the same\r\n",
        "# We can overwrite suicide_norm\r\n",
        "data[\"suicide_norm\"] = round(data[\"suicides_no\"] / data[\"population\"] * 100000,  2)"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CIsMjQ29mnjU"
      },
      "source": [
        "#Classification\r\n",
        "target = data[\"age\"]\r\n",
        "data.sex.replace({'male':1,'female':0}, inplace=True)\r\n",
        "features = data[[\"sex\", \"suicides_no\", \"year\"]]\r\n",
        "\r\n",
        "                          \r\n",
        "#features = pd.get_dummies(features, columns=[\"sex\", \"year\", \"generation\", \"country\"])\r\n"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p8kVvhipaFwC"
      },
      "source": [
        "# Data preparatation. \r\n",
        "# Create standardizer and standardize features\r\n",
        "features_standardized = StandardScaler().fit_transform(features)\r\n",
        "# use train and test split\r\n",
        "# multiple classification, gr = 3\r\n",
        "x, x_out, y, y_out = train_test_split(features_standardized, target, test_size = 0.1, random_state = 0)  # for multiple category clasification\r\n",
        "# binary classification, gr = 2\r\n",
        "x2, x2_out, y2, y2_out = train_test_split(features_standardized[:100,], target[:100], test_size = 0.1, random_state = 0)  # for binary clasification"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "voDJtGmCfm32",
        "outputId": "eae89133-1115-4936-af79-4a9a716106fc"
      },
      "source": [
        "# Create logistic regression object\r\n",
        "log_regr = LogisticRegression(random_state=0)\r\n",
        "# Train model\r\n",
        "cv_log_reg = cross_validate(log_regr, x2, y2, cv=10, error_score=\"accuracy\", return_train_score=True)\r\n",
        "\r\n",
        "for key in [\"test_score\", \"train_score\"]:\r\n",
        "  print(key)\r\n",
        "  print(\"Accuracy: %0.2f (+/- %0.2f)\" % (cv_log_reg.get(key).mean(), cv_log_reg.get(key).std() * 2))\r\n",
        "# 2 SD is roughly 95 % of data.\r\n",
        "\r\n",
        "log_regr.fit(x2, y2) # train\r\n",
        "\r\n",
        "# about model\r\n",
        "log_regr.classes_\r\n",
        "log_regr.coef_\r\n",
        "log_regr.intercept_\r\n",
        "\r\n",
        "log_regr.predict(x2_out)  # predictions\r\n",
        "log_regr.predict_proba(x2_out) # prediction probabilities\r\n",
        "\r\n",
        "pred_out = log_regr.predict(x2_out)\r\n",
        "pred_train = log_regr.predict(x2)\r\n",
        "\r\n",
        "print('The accuracy of the Logistic Regression is', metrics.accuracy_score(log_regr.predict(x2_out), y2_out))\r\n"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test_score\n",
            "Accuracy: 0.04 (+/- 0.11)\n",
            "train_score\n",
            "Accuracy: 0.20 (+/- 0.02)\n",
            "The accuracy of the Logistic Regression is 0.0\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}